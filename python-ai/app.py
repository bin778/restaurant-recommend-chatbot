import os
import json
import urllib.request
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
from dotenv import load_dotenv
import google.generativeai as genai
import requests
from contextlib import asynccontextmanager

# .env ë¡œë“œ ë° API ì„¤ì •
load_dotenv()
app = FastAPI()
genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
model = genai.GenerativeModel('gemini-2.5-flash')
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")
SPRING_BOOT_API_URL = "https://localhost:8443"
filtered_keywords = set()

# Pydantic ëª¨ë¸ ì •ì˜
class Message(BaseModel):
    sender: str
    text: str

class RecommendRequest(BaseModel):
    messages: List[Message]

class RecommendResponse(BaseModel):
    reply: str

# ì„œë²„ ì‹œì‘ ì‹œ í•„í„°ë§ í‚¤ì›Œë“œ ë¡œë“œ
def load_filtered_keywords():
    global filtered_keywords
    try:
        # Spring Bootì˜ ê³µê°œ API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í‚¤ì›Œë“œ ëª©ë¡ì„ ê°€ì ¸ì˜´
        response = requests.get(f"{SPRING_BOOT_API_URL}/api/public/filtered-keywords", verify=False)
        if response.status_code == 200:
            keywords_list = response.json()
            filtered_keywords = set(keywords_list)
            print(f"âœ… í•„í„°ë§ í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ: {len(filtered_keywords)}ê°œ")
    except Exception as e:
        print(f"âŒ í•„í„°ë§ í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# FastAPI Lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë  ë¡œì§
    load_filtered_keywords()
    yield
    # ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ë¡œì§ (í•„ìš” ì‹œ ì¶”ê°€)
    print("ì„œë²„ê°€ ì¢…ë£Œë©ë‹ˆë‹¤.")

# FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ lifespan ì ìš©
app = FastAPI(lifespan=lifespan)

# ë„¤ì´ë²„ ê²€ìƒ‰ í•¨ìˆ˜
def search_naver_local(query: str) -> dict:
    print(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/local.json?query={encText}&display=10"
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            return json.loads(response.read().decode('utf-8'))
    except Exception as e:
        print(f"ë„¤ì´ë²„ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return None

# API ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/refresh-keywords")
async def refresh_keywords():
    print("ğŸ”„ í‚¤ì›Œë“œ ëª©ë¡ ìƒˆë¡œê³ ì¹¨ ìš”ì²­ ìˆ˜ì‹ . ê°±ì‹ ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    load_filtered_keywords()
    return {"message": "Keywords refreshed successfully."}

@app.post("/api/recommend", response_model=RecommendResponse)
async def recommend_restaurant(request: RecommendRequest):
    conversation_history = request.messages
    latest_user_message = conversation_history[-1].text if conversation_history else ""
    print(f"ì „ë‹¬ë°›ì€ ëŒ€í™”ê¸°ë¡: {conversation_history}")

    # ì‚¬ìš©ì ë©”ì‹œì§€ í•„í„°ë§
    for keyword in filtered_keywords:
        if keyword.lower() in latest_user_message.lower():
            print(f"ğŸš« ë¶€ì ì ˆ í‚¤ì›Œë“œ '{keyword}' ê°ì§€. ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return RecommendResponse(reply="ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì£¼ì œì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?")

    try:
        # 1ë‹¨ê³„ (ì‹ ê·œ): ì˜ë„ ë° ê°ì • ë¶„ì„
        intent_analysis_prompt = f"""
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ëŒ€í™” ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤.
        ì•„ë˜ [ëŒ€í™” ê¸°ë¡]ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ë³´ê³ , ì˜ë„ë¥¼ 'ë§›ì§‘ ì¶”ì²œ' ë˜ëŠ” 'ì¼ë°˜ ëŒ€í™”'ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
        ë§Œì•½ 'ë§›ì§‘ ì¶”ì²œ' ì˜ë„ë¼ë©´, ì‚¬ìš©ìì˜ ê¸°ë¶„(ì˜ˆ: ìš°ìš¸í•¨, ì‹ ë‚¨), ë‚ ì”¨(ì˜ˆ: ë¹„ ì˜¤ëŠ” ë‚ ), ë§› ì·¨í–¥(ì˜ˆ: ë‹¬ë‹¬í•œ, ë§¤ì½¤í•œ)ê³¼ ê´€ë ¨ëœ 'ê°ì„±/ìƒí™© í‚¤ì›Œë“œ'ë¥¼ í•¨ê»˜ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

        [ëŒ€í™” ê¸°ë¡]
        {json.dumps([msg.dict() for msg in conversation_history], ensure_ascii=False)}

        [JSON ì¶œë ¥ í˜•ì‹]
        {{"intent": "ë§›ì§‘ ì¶”ì²œ" or "ì¼ë°˜ ëŒ€í™”", "sentiment_keywords": "ê°ì„±/ìƒí™© í‚¤ì›Œë“œ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´"}}
        """
        intent_response = model.generate_content(intent_analysis_prompt)
        intent_data = json.loads(intent_response.text.strip().lstrip("```json").rstrip("```"))
        print(f"ì˜ë„ ë¶„ì„ ê²°ê³¼: {intent_data}")
        
        intent = intent_data.get("intent")
        sentiment = intent_data.get("sentiment_keywords", "")

        # ë¶„ê¸° ì²˜ë¦¬: ì¼ë°˜ ëŒ€í™” vs ë§›ì§‘ ì¶”ì²œ
        if intent == "ì¼ë°˜ ëŒ€í™”":
            general_response_prompt = f"""
            ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë§ì— ì¹œì ˆí•˜ê²Œ ê³µê°í•˜ë©° ì‘ë‹µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
            ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•´ ì§§ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ì²œë§Œì—ìš”! ë„ì›€ì´ ë˜ì…¨ë‹¤ë‹ˆ ì €ë„ ê¸°ì˜ë„¤ìš”. ğŸ˜Š")

            ì‚¬ìš©ì ë©”ì‹œì§€: "{latest_user_message}"
            """
            bot_reply = model.generate_content(general_response_prompt).text
            return RecommendResponse(reply=bot_reply)

        # 2ë‹¨ê³„: ë§›ì§‘ ì¶”ì²œì„ ìœ„í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_extraction_prompt = f"""
        [ëŒ€í™” ê¸°ë¡]ê³¼ [ê°ì„±/ìƒí™© í‚¤ì›Œë“œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë„¤ì´ë²„ ì§€ë„ ê²€ìƒ‰ì— ì‚¬ìš©í•  ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.

        [ì§€ì‹œì‚¬í•­]
        1. 'topics': ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ìŒì‹, ë¸Œëœë“œ, ë§›(ì˜ˆ: ë§¤ìš´, ë‹¬ë‹¬í•œ)ì„ **ëª¨ë‘ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ**ë¡œ ì¶”ì¶œí•´ì¤˜.
        2. 'locations': ì‚¬ìš©ìê°€ ë§ˆì§€ë§‰ì— ì–¸ê¸‰í•œ ì§€ì—­ëª… ë¦¬ìŠ¤íŠ¸ì•¼.
        3. 'is_franchise': 'topics'ì— 'ìŠ¤íƒ€ë²…ìŠ¤', 'í”„ë­í¬ë²„ê±°', 'BHC'ì™€ ê°™ì´ ëª…í™•í•œ í”„ëœì°¨ì´ì¦ˆ ì´ë¦„ì´ í¬í•¨ë˜ë©´ trueë¡œ ì„¤ì •í•´ì¤˜.
        4. 'exclude_list': ì´ì „ ì±—ë´‡ ë‹µë³€ì—ì„œ ì´ë¯¸ ì¶”ì²œí–ˆë˜ ê°€ê²Œ ì´ë¦„ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ì•¼.
        5. 'ë¹„ ì˜¤ëŠ” ë‚ ' -> 'íŒŒì „, ì¹¼êµ­ìˆ˜', 'ìš°ìš¸í•œ ë‚ ' -> 'ë‹¬ë‹¬í•œ ì¼€ì´í¬, ë§¤ìš´ ë–¡ë³¶ì´' ì²˜ëŸ¼ ìƒí™©ì„ ê²€ìƒ‰ ê°€ëŠ¥í•œ ìŒì‹ í‚¤ì›Œë“œë¡œ ë³€í™˜í•´ì„œ 'topics'ì— ì¶”ê°€í•´ì¤˜.

        [ëŒ€í™” ê¸°ë¡]: {json.dumps([msg.dict() for msg in conversation_history], ensure_ascii=False)}
        [ê°ì„±/ìƒí™© í‚¤ì›Œë“œ]: "{sentiment}"

        [JSON ì¶œë ¥ í˜•ì‹]
        {{"topics": ["ìŒì‹/ë¸Œëœë“œ1", "ë§›1"], "locations": ["ì§€ì—­ëª…1"], "is_franchise": true/false, "exclude_list": ["ì¶”ì²œí–ˆë˜ ê°€ê²Œ1"]}}
        """
        keyword_response = model.generate_content(keyword_extraction_prompt)
        keywords = json.loads(keyword_response.text.strip().lstrip("```json").rstrip("```"))
        print(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")

        # 3ë‹¨ê³„: ì™¸ë¶€ ë°ì´í„° ê²€ìƒ‰
        all_search_items = []
        if keywords.get("locations"):
            for location in keywords["locations"]:
                for topic in keywords.get("topics", ["ë§›ì§‘"]):
                    query_suffix = "" if keywords.get("is_franchise") else " ë§›ì§‘"
                    search_query = f"{location} {topic}{query_suffix}"
                    search_results = search_naver_local(search_query.strip())
                    if search_results and search_results.get("items"):
                        all_search_items.extend(search_results["items"])
        
        # 4ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±
        exclude_list = keywords.get("exclude_list", [])
        filtered_items = [item for item in all_search_items if item.get('title', '').replace('<b>', '').replace('</b>', '') not in exclude_list]
        unique_items = list({item['link']: item for item in filtered_items}.values())

        if not unique_items:
            bot_reply = "ì£„ì†¡í•©ë‹ˆë‹¤, ì›í•˜ì‹œëŠ” ì¡°ê±´ì˜ ë§›ì§‘ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. í‚¤ì›Œë“œë¥¼ ì¡°ê¸ˆ ë°”ê¿”ì„œ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"
        else:
            context_info = "\n".join([f"- {item.get('title', '').replace('<b>', '').replace('</b>', '')} (ì£¼ì†Œ: {item.get('address', '')}, ì¹´í…Œê³ ë¦¬: {item.get('category', '')})" for item in unique_items[:5]])

            generation_prompt = f"""
            ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°ì •ê¹Œì§€ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜•ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ”, ë‹¤ì •ë‹¤ê°í•œ ë§›ì§‘ íë ˆì´í„°ì•¼.

            [ì§€ì‹œì‚¬í•­]
            1. [ì‚¬ìš©ì ê°ì„±]ì„ ë°˜ì˜í•˜ì—¬, ë”°ëœ»í•˜ê²Œ ê³µê°í•˜ëŠ” ì²«ì¸ì‚¬ë¡œ ë‹µë³€ì„ ì‹œì‘í•´ì¤˜.
            2. 'ê²€ìƒ‰ëœ ë§›ì§‘ ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ê°€ê²Œë¥¼ ìµœëŒ€ 5ê³³ê¹Œì§€ ì„ ì •í•´ì„œ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì„¤ëª…í•´ì¤˜.
            3. ì¶”ì²œí•  ê°€ê²Œê°€ 2ê°œ ì´í•˜ì´ë©´, ê° ê°€ê²Œì— ëŒ€í•´ ìƒì„¸í•˜ê³  ë§¤ë ¥ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ê³ , 3ê°œ ì´ìƒì´ë©´ í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜.
            4. ê°€ê²Œ ì´ë¦„ì— 'DT'ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ "(ë“œë¼ì´ë¸ŒìŠ¤ë£¨ ê°€ëŠ¥)" ì´ë¼ê³  ë§ë¶™ì—¬ì¤˜.
            5. ë§ˆì§€ë§‰ì—ëŠ” "ì´ ì¶”ì²œì´ ë§ˆìŒì— ë“œì…¨ìœ¼ë©´ ì¢‹ê² ë„¤ìš”! ê¸°ë¶„ ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”. ğŸ˜„" ì™€ ê°™ì´ ë‹¤ì–‘í•˜ê³  ê¸ì •ì ì¸ ë§ˆë¬´ë¦¬ ì¸ì‚¬ë¥¼ ê±´ë„¤ì¤˜.
            6. ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´(`**` ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆ.

            [ì‚¬ìš©ì ê°ì„±]: "{sentiment}"
            [ì‚¬ìš©ì ì§ˆë¬¸]: "{latest_user_message}"
            [ê²€ìƒ‰ëœ ë§›ì§‘ ì •ë³´]: {context_info}
            [ë„ˆì˜ ë‹µë³€]:
            """
            final_response = model.generate_content(generation_prompt)
            bot_reply = final_response.text

        print(f"ìµœì¢… ìƒì„±ëœ ë‹µë³€: {bot_reply}")
        return RecommendResponse(reply=bot_reply)

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
