import json, os
import google.generativeai as genai
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from services import search_naver_local, scrape_naver_place_details

genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
model = genai.GenerativeModel('gemini-2.5-flash')

class Message(BaseModel):
    sender: str
    text: str

async def process_recommendation_request(
    conversation_history: List[Message],
    filtered_keywords: set,
    current_location: Optional[str] = None
) -> str:
    """
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë°›ì•„ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    latest_user_message = conversation_history[-1].text if conversation_history else ""

    # --- ì‚¬ìš©ì ë©”ì‹œì§€ í•„í„°ë§ ---
    for keyword in filtered_keywords:
        if keyword.lower() in latest_user_message.lower():
            print(f"ğŸš« ë¶€ì ì ˆ í‚¤ì›Œë“œ '{keyword}' ê°ì§€.")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì£¼ì œì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # --- Few-shot ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ì§€ëŠ¥ì„ ê³ ë„í™”í•œ í†µí•© í”„ë¡¬í”„íŠ¸ ---
    combined_analysis_prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬, ê·¸ ì˜ë„ì— ë”°ë¼ ë‹¤ìŒ ì„¸ ê°€ì§€ ì‘ì—… ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë©€í‹°íƒœìŠ¤í‚¹ AIì…ë‹ˆë‹¤.

    [ì‘ì—… íë¦„]
    1. ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì˜ ì˜ë„ë¥¼ 'ë§›ì§‘ ì¶”ì²œ', 'ìƒì„¸ ì •ë³´ ì§ˆë¬¸', 'ì¼ë°˜ ëŒ€í™”' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    2. ì˜ë„ê°€ 'ì¼ë°˜ ëŒ€í™”'ì´ë©´, 'reply' í•„ë“œì— ì§ì ‘ ë‹µë³€ì„ ìƒì„±í•˜ê³  ë‚˜ë¨¸ì§€ í•„ë“œëŠ” nullë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    3. ì˜ë„ê°€ 'ë§›ì§‘ ì¶”ì²œ'ì´ë©´, 'reply'ëŠ” nullë¡œ ë‘ê³ , ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ì— í•„ìš”í•œ 'search_keywords'ì™€ 'sentiment_keywords'ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    4. ì˜ë„ê°€ 'ìƒì„¸ ì •ë³´ ì§ˆë¬¸'ì´ë©´, 'reply'ëŠ” nullë¡œ ë‘ê³ , ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•˜ëŠ” ê°€ê²Œ ì •ë³´ì¸ 'detail_query'ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    [ì¶”ì¶œ ì§€ì‹œì‚¬í•­]
    - sentiment_keywords: ì‚¬ìš©ìì˜ ê¸°ë¶„, ë‚ ì”¨, ë§› ì·¨í–¥ ë“± ê°ì„±/ìƒí™© í‚¤ì›Œë“œ.
    - search_keywords: ë§›ì§‘ ì¶”ì²œ ê²€ìƒ‰ì–´. {{ "topics": [...], "locations": [...], "exclude_list": [...] }} í˜•ì‹.
    - detail_query: ìƒì„¸ ì •ë³´ ì§ˆë¬¸. {{ "target_restaurant": "...", "requested_details": "..." }} í˜•ì‹.

    ---
    [Few-shot ì˜ˆì‹œ]

    # ì˜ˆì‹œ 1: ê°ì„± í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë§›ì§‘ ì¶”ì²œ ì§ˆë¬¸
    - ëŒ€í™” ê¸°ë¡: [{{"sender": "user", "text": "ì˜¤ëŠ˜ ë„ˆë¬´ ìš°ìš¸í•´ì„œ ê·¸ëŸ°ë°, ê°•ë‚¨ì—ì„œ ë‹¬ë‹¬í•œ ë””ì €íŠ¸ ë§›ìˆëŠ” ê³³ ì¢€ ì•Œë ¤ì¤˜"}}]
    - ì¶œë ¥:
    {{
        "intent": "ë§›ì§‘ ì¶”ì²œ",
        "reply": null,
        "sentiment_keywords": "ìš°ìš¸í•œ, ë‹¬ë‹¬í•œ",
        "search_keywords": {{
            "topics": ["ë‹¬ë‹¬í•œ ë””ì €íŠ¸", "ì¼€ì´í¬", "ì¹´í˜"],
            "locations": ["ê°•ë‚¨"],
            "exclude_list": []
        }},
        "detail_query": null
    }}

    # ì˜ˆì‹œ 2: íŠ¹ì • ê°€ê²Œì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì§ˆë¬¸
    - ëŒ€í™” ê¸°ë¡: [
        {{"sender": "user", "text": "ìƒìˆ˜ì—­ ê·¼ì²˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜"}},
        {{"sender": "assistant", "text": "ë„¤, ìƒìˆ˜ì—­ ê·¼ì²˜ ë§›ì§‘ìœ¼ë¡œ 'í›„ë¼í† ì‹ë‹¹'ê³¼ 'ì˜¤ì± 'ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”."}},
        {{"sender": "user", "text": "í›„ë¼í† ì‹ë‹¹ ì˜ì—…ì‹œê°„ì´ ì–´ë–»ê²Œ ë¼?"}}
    ]
    - ì¶œë ¥:
    {{
        "intent": "ìƒì„¸ ì •ë³´ ì§ˆë¬¸",
        "reply": null,
        "sentiment_keywords": null,
        "search_keywords": null,
        "detail_query": {{
            "target_restaurant": "í›„ë¼í† ì‹ë‹¹ ìƒìˆ˜ì ",
            "requested_details": "ì˜ì—…ì‹œê°„"
        }}
    }}

    # ì˜ˆì‹œ 3: ê°„ë‹¨í•œ ì¼ë°˜ ëŒ€í™”
    - ëŒ€í™” ê¸°ë¡: [{{"sender": "user", "text": "ê³ ë§ˆì›Œ!"}}]
    - ì¶œë ¥:
    {{
        "intent": "ì¼ë°˜ ëŒ€í™”",
        "reply": "ì²œë§Œì—ìš”! ë˜ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”.",
        "sentiment_keywords": null,
        "search_keywords": null,
        "detail_query": null
    }}
    ---

    [ì‹¤ì œ ë¶„ì„ ëŒ€ìƒ]

    [ëŒ€í™” ê¸°ë¡]
    {json.dumps([msg.dict() for msg in conversation_history], ensure_ascii=False)}

    [JSON ì¶œë ¥ í˜•ì‹]
    {{ "intent": "...", "reply": "...", "sentiment_keywords": "...", "search_keywords": {{...}}, "detail_query": {{...}} }}
    """
    
    analysis_response = model.generate_content(combined_analysis_prompt)
    # JSON ë¬¸ìì—´ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í›„ì²˜ë¦¬
    response_text = analysis_response.text.strip()
    json_part = response_text[response_text.find('{'):response_text.rfind('}')+1]
    analysis_data = json.loads(json_part)

    print(f"í†µí•© ë¶„ì„ ê²°ê³¼: {analysis_data}")
    
    intent = analysis_data.get("intent")

    if intent == "ì¼ë°˜ ëŒ€í™”":
        return analysis_data.get("reply", "ë„¤, ë§ì”€í•˜ì„¸ìš”.")

    # --- ì˜ë„ì— ë”°ë¥¸ ì •ë³´ ê²€ìƒ‰ (Retrieval) ---
    context_info = ""
    
    if intent == "ìƒì„¸ ì •ë³´ ì§ˆë¬¸":
        detail_query = analysis_data.get("detail_query")
        target_restaurant = detail_query.get("target_restaurant") if detail_query else None
        if target_restaurant:
            # ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIëŠ” ì •í™•ë„ë¥¼ ìœ„í•´ 'target_restaurant' ê·¸ëŒ€ë¡œ ì‚¬ìš©
            search_results = search_naver_local(target_restaurant)
            if search_results and search_results.get("items"):
                first_item = search_results["items"][0]
                place_url = first_item.get("link")

                is_place_url = place_url and ('map.naver.com' in place_url or 'm.place.naver.com' in place_url)
                if is_place_url:
                    context_info = scrape_naver_place_details(place_url)
                else:
                    context_info = f"'{target_restaurant}'ì˜ ë„¤ì´ë²„ ì§€ë„ ìƒì„¸ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            else:
                context_info = f"'{target_restaurant}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
             context_info = "ì–´ë–¤ ê°€ê²Œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ê°€ê²Œ ì´ë¦„ì„ ë§ì”€í•´ì£¼ì„¸ìš”."

    elif intent == "ë§›ì§‘ ì¶”ì²œ":
        keywords = analysis_data.get("search_keywords")
        if not keywords or not keywords.get("locations"):
            if current_location:
                keywords = keywords or {}
                keywords["locations"] = [current_location]
            else:
                return "ì–´ë”” ê·¼ì²˜ì˜ ë§›ì§‘ì„ ì°¾ì•„ë“œë¦´ê¹Œìš”? ì§€ì—­ì„ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•˜ê²Œ ì¶”ì²œí•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”."
        
        all_search_items = []
        for location in keywords.get("locations", []):
            for topic in keywords.get("topics", ["ë§›ì§‘"]):
                search_query = f"{location} {topic}"
                search_results = search_naver_local(search_query)
                if search_results and search_results.get("items"):
                    # exclude_listì— í¬í•¨ëœ ê°€ê²ŒëŠ” ì¶”ì²œì—ì„œ ì œì™¸
                    exclude_list = keywords.get("exclude_list", [])
                    filtered_items = [
                        item for item in search_results["items"]
                        if not any(ex_item in item.get('title', '').replace('<b>', '').replace('</b>', '') for ex_item in exclude_list)
                    ]
                    all_search_items.extend(filtered_items)
        
        unique_items = list({item['link']: item for item in all_search_items}.values())
        context_info = "\n".join([f"- ìƒí˜¸ëª…: {item.get('title', '').replace('<b>', '').replace('</b>', '')}, ì£¼ì†Œ: {item.get('address', '')}, ì¹´í…Œê³ ë¦¬: {item.get('category', '')}" for item in unique_items[:5]])

    # --- ìµœì¢… ë‹µë³€ ìƒì„± (Generation) ---
    if not context_info:
        sentiment_keywords = analysis_data.get("sentiment_keywords")
        if intent == "ë§›ì§‘ ì¶”ì²œ" and sentiment_keywords:
             return f"{sentiment_keywords}ì— ì–´ìš¸ë¦¬ëŠ” ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ ì¥ì†Œë‚˜ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì •ë³´ë¥¼ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"

    generation_prompt = f"""
    ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, [ì£¼ì–´ì§„ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ë§›ì§‘ íë ˆì´í„°ì•¼.
    
    [ì§€ì‹œì‚¬í•­]
    1. [ì£¼ì–´ì§„ ì •ë³´]ë¥¼ ì™„ë²½í•˜ê²Œ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì„œ ë‹µë³€í•´ì¤˜.
    2. ì‚¬ìš©ìê°€ 'ì˜ì—…ì‹œê°„', 'ë©”ë‰´' ë“±ì„ ë¬¼ì–´ë³´ë©´, ì •ë³´ì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì•„ë‚´ì„œ ì•Œë ¤ì¤˜.
    3. ë§Œì•½ ì •ë³´ì— ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ì•„ì‰½ê²Œë„ ì œê°€ ê°€ì§„ ì •ë³´ì—ëŠ” ì˜ì—…ì‹œê°„ì´ ë‚˜ì™€ìˆì§€ ì•Šë„¤ìš”." ì™€ ê°™ì´ ì†”ì§í•˜ê²Œ ë‹µë³€í•´ì¤˜.
    4. ì ˆëŒ€ [ì£¼ì–´ì§„ ì •ë³´]ì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ì¸¡í•´ì„œ ë§í•˜ì§€ ë§ˆ.
    5. ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´(`**` ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆ.

    [ì‚¬ìš©ì ì§ˆë¬¸]: "{latest_user_message}"
    [ì£¼ì–´ì§„ ì •ë³´]:
    {context_info}

    [ë„ˆì˜ ë‹µë³€]:
    """
    final_response = model.generate_content(generation_prompt)
    bot_reply = final_response.text

    print(f"ìµœì¢… ìƒì„±ëœ ë‹µë³€: {bot_reply}")
    return bot_reply